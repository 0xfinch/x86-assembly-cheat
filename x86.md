Very popular architecture family by Intel.

The official name is IA-32 commonly known as x86 or x86-32 or i386.

This section shall contain info on the entire family.

Majority of PCs use it as of 2013. Cell phones use ARM mainly.

AMD also produces CPUs with a compatible interface.

CISC.

Backwards compatible to the 1970s!

#sources

[ia32-man]: http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html

- [ia32-man][]

    Intel man pages, *the* official source.

[wiki-instr-list]: http://en.wikipedia.org/wiki/X86_instruction_listings

- [wiki-instr-list][]

    Instruction list.

#history

##intel 8080

1974, 8 bit, 2MHz, very popular

##intel 8086

1976, 16 bit, very popular, base to x86 language

##intel 80386

aka i386

1985, 32 bit word register

##intel 8087

1980

external floating point co-processor for the 8086

in other words: this is not a CPU, but something external to the CPU,
which the CPU could interface with.

included inside CPUs starting from the 80436

x87 often used to describe the floating point operations
inside the processors

instructions include:

- FSQRT
- FSIN

##intel 80486

1989

includes floating point unity inside of it

#syntaxes

there is no de facto standard for the computer syntax

##intel

used to document intel x86 at first

more popular on windows

used by nasm and masm

###at&t

more popular for linux, since UNIX was created at bell labs,
and since gnu uses at&t syntax as backend and as the primary inline assembly language.

#pinout

it is a good idea to understand what are the physical pins of the processor and
what they do to understand what is actually going on when you do instructions

![8086 pinout a](8086-pinout.gif "8086 pinout")

![80387 pinout a](80387-pinout.gif "80387 pinout")

TODO understand

#registers

Registers store data in the processor.

Most CPU operations operate on and or use registers values.

There are very few registers compared to RAM slots because of the memory hierarchy tradeoff:
CPU register access is extremely fast, but the cost of each register is extremely high.

Suffixes:

- B: byte
- W: word = 2 bytes
- D: double word = 2 words (a c `int`)
- Q: quad word
- T: ten bytes

##access modes

For 32 bit registers, most instructions allow to operate on either:

- 32 bits. called extended. ex: `eax`
- 16 lower bits. ex: `ax`
- 8 lower bits. `al`
- 8 upper bits. `au`

list of all registers.

##general purpose registers

there are 8 general-purpose 32 bit registers (gpr):

- eax
- ebx
- ecx
- edx
- ESI
- EDI
- EBP
- ESP: used stack pointer.

In theory, those can be used freely for many computations
such as sums, subtractions, etc

However, some instructions make extensive use of certain of those registers
such as `ESP` which keeps track of the stack.

Therefore, you should rely primarily on `eax`, `ebx` and `ecx` as actually being general purpose,
and even for those you should check often if each operation will not take input/output from them
without you knowing it.

##flags register

Each bit represents a boolean

Types:

- FLAGS: 16 lower bits
- EFLAGS: (extended) refers to the 16 upper bits only, or the entire register

some of those values may be modified as of by other operations
such as comparisons or sums, to indicate certain conditions

some of the flags are:

- SF sign

- ZF zero

1 if result == 0

- PF parity

0 lower 8 bits of result

- CF carry

- OF overflow

- AF adjust

- IF interrupt flag

this flag says if interrupts are enabled or disabled in the current processor

this can be useful for synchronization

it can only be set / cleared by a processes with sufficient privileges
normally one that runs in kernel space, such as kernel code of as a linux kernel module

for that reason, its usage cannot be demonstrated here,
but only in an OS depend ant manner.

all flags can be identified by a single letter. Ex: zero flag Z, sign flag S.

###flag instructions

flags have the following operations defined

- clear: clX.  flag = 0
- set: stX.    flag = 1
- complement: cmX.    flag = !flag

all flags also have short jump instructions:

- jX:  jump if X == 1
- jnX: jump if X == 0

##segment instruction pointer register

A 32 bit segment instruction pointer called EIP.

Points to the address of the next instruction to be executed

Is normally increased by 4 bytes after the execution of each instruction

It can be read by use applications.

##segment registers

They are usually only useful for operating system writers,
and can only be modified when in kernel mode.

See [this](#segmentation) for an explanation of what those do.

User level programs usually do not have permission to modify those registers.

- 6 16 bit segment registers

    - SS: start of stack segment
    - DS: start of data segment
    - CS: start of code segment
    - ES, FG, GS: are free for programs to define.

Each segment register has a corresponding read only 8 byte Segment descriptor register,
which automatically pulled in from RAM when a segment is changed.

##cr registers

Control registers, cr0 to cr4.

Usually not accessible by user applications, only kernel mode.

Control very important parameters of the mode of operation of the processor.

Their exact functions may be too complicated to describe here,
and will be left for other sections.

- cr0:

    1 bit flags that determine how the CPU operates.

    Some of the flags are:

    1   2   3                       4
    --  --  --                      --
    31 	PG 	Paging 	                If 1, enable paging and use the CR3 register, else disable paging

    30 	CD 	Cache disable 	        Globally enables/disable the memory cache

    29 	NW 	Not-write through 	    Globally enables/disable write-back caching

    18 	AM 	Alignment mask 	        Alignment check enabled if AM set, AC flag (in EFLAGS register) set, and privilege level is 3

    16 	WP 	Write protect 	        Determines whether the CPU can write to pages marked read-only

    0 	PE 	Protected Mode Enable 	If 1, system is in protected mode, else system is in real mode

- cr1: reserved by Intel for future use.

- cr2:

    Used by the paging system.

    After a segmentation fault, stores the value of the address access attempt that caused the fault.

- cr3:

    Used by the paging system.

    Points to the current Page Table, Directory, or Pointer table depending on the values of PAE and PSE.

- cr4:

    1 bit flags that determine how the CPU operates.

    Some of the flags are:

    1   2    3                           4
    --  --   --                          --
    5   PAE	 Physical Address Extension  If set, changes page table layout to translate 32-bit virtual addresses into extended 36-bit physical addresses.
    4   PSE	 Page Size Extension 	     If unset, page size is 4 KB, else page size is increased to 4 MB (or 2 Mob with PAE set).

##other registers

- FPU registers for floating point operations
- SIMD registers MMX and XMM for SIMD instructions

#calling conventions

Determine exactly how functions are called on the assembly level.

Sources:

[wiki-x86-callconv]: http://en.wikipedia.org/wiki/X86_calling_conventions

- [wiki-x86-callconv][]

##cdecl

De facto standard C calling convention used by GCC.

Does not have a formal standard, so different compilers may have incompatible versions of cdecl.

- return address is put on the stack ( usually via call/ret instructions )

- args are passed on stack

    - always pass dword args

        If you want to pass a single byte, first convert to dword

    - args are put on stack in inverse order from declaration

        This allows for funcs with arbitrary numbers of args such as `printf`:

        Like this the format string will always be on the same position (at the end).

    - args are not popped before return.

        If you want to use their values, use ESP pointer

- return value is put in:

    - eax if integer or pointer.

        If 64-bit, put in edx:eax.

    - ST0 x87 register if floating point.

    - for structures, there is some divergence between different compilers.

        For small structures, some compilers may choose to return the struct on multiple registers such as EAX and EDX.

        For larger structures which do not fit into registers, a common technique is for the compiler to automatically add
        a hidden pointer parameter to the function and automatically make the caller allocate memory and pass a pointer to that memory.

- EAX, ECX and EDX may change after the call and must be saved by the caller
    if he wants to keep those.

    All other registers are guaranteed not to change after the call.
    They may be temporarily changed inside

- the caller clears the argument heap

    This generates more code since programs usually make several for each definition,

    This allows for functions with variable number or arguments such as `printf`,
    because then only the caller knows how many args he put on the stack.

    PASCAL for example follows a function clear argument stack convention.

##C calling convention

ANSI C does not specify assembly level calling convention to be used by implementations
nor means to control actual calling conventions.

Some compilers do however contain extensions that allow to fix a given calling convention.

gcc allows to specify calling convention explicitly as:

    void f ( int ) __attribute__ ((cdecl ));

`cdecl` is the name of the calling convention.

As OS 2013, cdecl is widely used as default across many compilers.

#call C functions

To call a C function from assembly you need to:

- use the correct C calling convention to which the C code compiled to.

    Remember that ANSI C does not specify this.

- use the correct naming convention of the libraries you want to link to.

    For example, `exit` may be called `_exit` on certain compilers such as GCC elf format.

    This is not specified by ANSI C, so the only portable alternative is via macros.

- declare the function you want to call as extern.

    nasm for example has the `extern` directive.

- compile into an object file and then compile that object file with the C object files.

    For example with nasm:

        nasm -o a.o a.asm
        gcc -c c.c -o c.o
        gcc -o main a.o c.o

    You can also call stdlib functions if you want, since gcc links to them for you.

#rings

IA-32 implements a hardware protection privilege system.

There are in total 4 privilege levels, also called rings, from 0 to 3,
but most operating systems use only 2: kernel space and user space, usually
with values 0 and 3.

Rings are useful for OS programmers.
The OS lets user programs run a restricted set of operations
limiting the amount of damage that a badly working or badly intentioned program can do.
Obviously this only works because user programs are then in a state in which they cannot
modify their own privilege levels without the OS intervening.

Certain operations such are only allowed if certain privileges are given.

Privilege control is only available on protected mode, and is managed by segmentation and paging.

#real mode

The other memory operation mode besides protected mode

#protected mode

Is the normal mode of operation.

The other main mode is called real mode, which exists mainly for backwards compatibility.

The processor starts on real mode only for backwards compatibility.

Starting from 386, mode is determined by the `PE` (protect enable) bit of the CR0 register.
If set, protected mode is active. If clear, real mode is active.

Protected mode furnishes two things: memory segmentation and paging.

Those two features are basic to modern operating system implementations.

The hardware supports these two feature to make it faster,
and automatically interacts with data stored on RAM when needed.

Before entering protected mode,
the software must first set up the required RAM data.

#address types

There are 3 types:

- logical
- linear
- physical

##logical address

A 16 bit segment + a 32 bit offset.

With segmentation, can be translated to a 32 bit address only.

##linear address

32 bit address, may be modified by paging before translation to a physical address.

##physical address

The actual electrical signals that go on the address memory cable.

#cache

##cache sources

[stallings11]: http://www.amazon.com/Operating-Systems-Internals-Principles-Edition/dp/013230998X

- [stallings11][] section "Cache Memory"

    Small and good intro on the subject.

##associativity

TODO0

##write back policy

- write through: always write to RAM immediately. Not efficient.

- not write through: writes to  RAM can happen only when the cache content is about to be invalidated.

    RAM remains on an outdated state for some time, which may lead to concurrency issues.

The policy can be controlled via the `NR` bit of `cr0`.

#segmentation

Only available on protected mode.

Makes the transition from logical to linear addresses.
Linear addresses are then converted to physical addresses (those that go to RAM wires)
by the paging circuits.

Its usage is obligatory on protected mode.

This feature was meant to be used to implement process virtual memory spaces,
but this usage has been mostly supplanted by a later implemented feature called paging.
In Linux for example, only two segments are used at all times:
one for the kernel, and one for all user processes.

##hardware implementation

Segmentation hardware uses RAM data structures called the global and local segment descriptor tables (GDT and LDT).

The format of those data structures is fixed *by the hardware*,
but it is up to the OS to set up and manage those data structures on RAM correctly,
and to tell the hardware where to find them
(via the `gdtr` and `ldtr` registers and the `lgdt` and `lldt` instructions).

Segmentation could be implemented in software but is hardware implemented because paging operations
are done at every single memory access and therefore need to be very fast.

##global descriptor table

RAM data structure that holds segment information.

The segment information data structure is called a *segment descriptor*.

Each segment descriptor is identified and retrieved via a *segment selector* structure.

##segment selector

A segment selector is a 16 bit structure that identifies the current segment descriptor
and the current privilege level.

It has the following fields:

- index: 13 bits to identify the Segment descriptor within the current table.

    There can therefore be up to 2^13 segment descriptors on a table.

    The current table is determined by the values of `gdtr` and `ldtr` registers
    and by the TI bit of the segment selector.

- RPL: Request privilege level.

    The privilege level of the code that will execute a Code segment.

- TI: 1 bit table indicator. If set, indicates that this is a local descriptor table.

    Otherwise, it is a global descriptor table.

##segment descriptor

Segment descriptors are kept in RAM, and are used by the hardware to translate logic to linear addresses.

It is up to the OS to set up and maintain segment descriptors on the RAM,
and to inform the hardware of its location via the `gdtr` and `ldtr` registers
The OS can modify those registers via the `lgdt` and `lldt` instructions.

Segment descriptors are kept inside tables which contain many contiguous segment descriptors called either global descriptor table
or local descriptor table.

Each segment descriptor is 8 bytes long, and contains information such as the following.

- BASE: 32 bit start address and end address of the segment

- LIMIT: 20 bit segment length. This is multiplied by $2^12$ if G is set
    so the maximum length is 4GB ($2^32$).

    Minimum length is 4 Kb.

- G: granularity flat. If set, LIMIT is in multiples of $2^12$ bytes, else multiples of 1 byte.

- DPL: 2 bit privilege level.

    Compared to the privilege level of the Segment Selector to determine if users have or not
    permission to take certain actions ( the rings are based on this )

- Type: 4 bit type field. Some of the types are:

    - Code: indicates a code segment. It is on this case the permissions to take actions are checked.

    - Data:

    - TSSD: task state segment descriptor. The segment contains saved register values (between process sleeps)

    - LDTD: the segment contains a local descriptor table

- S: system

    If set, indicates that the RAM of that segment contains important structures such as Local descriptor table.

The current segment descriptor is determined
by the current segment selector and the values of the `gdtr` and `ldtr` registers.

##segment registers

Segment registers contain segment selectors

There are 6 segment registers.

3 have special meanings:

- CS: code segment
- SS: data segment
- DS: data segment

And the other three don't and are free for programmer use.

- ES
- FG
- GS

Segment selectors can be put into those segment registers via `mov` instructions.

Each segment selector has an associated read only register which contains the corresponding
segment descriptor to that selector.

Segment descriptors are pulled into dedicated processor registers automatically
when a segment register changes value.

This allows to read segment descriptors from RAM only once when segments change,
and access them directly from the CPU the following times.

TODO which of those segments are used at each time?

##segment descriptor types

TODO what is the difference between types?

##example of address translation

TODO very important. One example, two programs running. Logical to linear address translation.

##linux

How Linux uses segments.

#paging

##general facts

Paging translates linear addresses ( what is left after segmentation translated logical addresses )
into physical addresses ( what actually goes go to RAM wires ).

Paging is only available on protected mode.
The use of paging protected mode is optional and if on iff the `PG` bit of `cr0` is set.

One major difference between paging and segmentation is that paging
logically splits RAM into equal sized chunks called pages, while segmentation
splits memory into chunks of arbitrary sizes. This makes things more manageable.

##application

Paging is used to implement processes virtual address spaces on modern OS.
With virtual addresses the OS can fit two or more concurrent processes on a single RAM in a way that:

- both programs need to know nothing about the other
- the memory of both programs can grow and shrink as needed
- the switch between programs is very fast
- one program can never access the memory of another process

Paging historically came after segmentation,
and largely replaced it for the implementation of virtual memory,
since it is easier to manage the fixed sized chunks of memory of pages instead
of variable length segments.

##hardware implementation

Just like for segmentation, paging hardware uses RAM data structures
( page tables, page directories, etc. ) to do its job.

The format of those data structures is fixed *by the hardware*,
but it is up to the OS to set up and manage those data structures on RAM correctly,
and to tell the hardware where to find them ( via `cr3` ).

Paging could be implemented in software but is hardware implemented because paging operations
are done at every single memory access and therefore need to be very fast.

##example: simplified paging scheme

This an example of how paging operates on a *simplified* version of a x86 architecture
to implement a virtual memory space.

###page tables

The OS could give them the following page tables:

Page table given to process 1 by the OS:

    RAM location        physical address   present
    -------------       -----------------  --------
    P1T + 0       * L   0x00001            1
    P1T + 1       * L   0x00000            1
    P1T + 2       * L   0x00003            1
    P1T + 3       * L                      0
    ...                                    ...
    P1T + 0xFFFFF * L   0x00005            1

Page table given to process 2 by the OS:

    RAM location       physical address   present
    -------------      -----------------  --------
    P2T + 0       * L  0x0000A            1
    P2T + 1       * L  0x0000B            1
    P2T + 2       * L                     0
    P2T + 3       * L  0x00003            1
    ...                ...                ...
    P2T + 0xFFFFF * L  0x00004            1

Where:

- P1T and P2T: initial position of table 1 and 2 on RAM.

    Sample values: `0x00000000`, `0x12345678`, etc.

    It is the OS that decides those values.

- L:   length of a page table entry.
- present: indicates that the page is present in memory.

Page tables are located on RAM. They could for example be located as:

    --------------> 0xFFFFFFFF


    --------------> P1T + 0xFFFFF * L
    Page Table 1
    --------------> P1T


    --------------> P2T + 0xFFFFF * L
    Page Table 2
    --------------> P2T

    --------------> 0x00000000

The initial locations on RAM for both page tables are arbitrary and controlled by the OS.
It is up to the OS to ensure that they don't overlap!

Each process cannot touch any page tables directly, although it can make requests to the OS
that cause the page tables to be modified, for example asking for larger stack or heap segments.

A page is a chunk of 4KB (12 bits), and since addresses have 32 bits,
only 20 bits ( 20 + 12 = 32, thus 5 characters in hexadecimal notation )
are required to identify each page.
This value is fixed by the hardware.

###page table entries

A page table is... a table of pages table entries!

The exact format of table entries if fixed *by the hardware*.

On this simplified example, the page table entries contain only two fields:

    bits   function
    -----  ---------
    20     physical address of the start of the page.
    1      present flag

so in this example the hardware designers could have chosen `L = 21`.

Most real page table entries have other fields.

It would be impractical to align things at 21 bytes since memory is addressable by bytes and not bits.
Therefore, even in only 21 bits are needed in this case, hardware designers would probably choose `L = 32`
to make access faster, and just reserve bits the remaining bits for later usage.
The actual value for `L` on x86 is 32 bits.

###address translation

Once the page tables have been set up by the OS, the address translation between linear
and physical addresses is done *by the hardware*.

The reason for this is that memory access is a very frequent operation,
and memory translation has to be done on every memory accesses,
so it would be too slow to do it via software.

When the OS wants to activate process 1, it sets the `cr3` to `P1T`,
the start of the table for process one.

If Process 1 wants to access linear address `0x00000001`,
the paging *hardware* circuit automatically does the following for the OS:

- split the linear address into two parts:

        | page (20 bits) | offset (12 bits) |

    So in this case we would have:

    - page = 0x00000
    - offset = 0x001

- look into Page table 1 because `cr3` points to it.

- look entry `0x00000` because that is the page part.

    The hardware knows that this entry is located at RAM address `P1T + 0 * L = P1T`.

- since it is present, the access is valid

- by the page table, the location of page number `0x00000` is at `0x00001 * 4K = 0x00001000`.

- to find the final physical address we just need to add the offset:

          00001 000
        + 00000 001
          -----------
          00001 001

    because `00001` is the physical address of the page looked up on the table and
    `001` is the offset.

    As the name indicates, the offset is always simply added the physical address of the page.

- the hardware then gets the memory at that physical location.

In the same way, the following translations would happen for process 1:

    linear     physical
    -------    ---------
    00000 002  00001 002
    00000 003  00001 003
    00000 FFF  00001 FFF
    00001 000  00000 000
    00001 001  00000 001
    00001 FFF  00000 FFF
    00002 000  00002 000
    FFFFF 000  00005 000

For example, when accessing address `0000100`, the page part is `00001` the hardware knows that its page table entry
is located at RAM address: `P1T + 1 * L` (`1` because of the page part), and that is where it will look for it.

When the OS wants to switch to process 2, all it needs to do is to make `cr3` point to page 2.
It is that simple!

Now the following translations would happen for process 2:

    linear     physical
    -------    ---------
    00000 002  00001 002
    00000 003  00001 003
    00000 FFF  00001 FFF
    00001 000  00000 000
    00001 001  00000 001
    00001 FFF  00000 FFF
    00003 000  00003 000
    FFFFF 000  00004 000

*The same linear address translates to different physical addresses for different processes*,
depending only on the value inside `cr3`.

In this way every program can expect its data to start at `0` and end at `FFFFFFFF`,
without worrying about exact physical addresses.

###page fault

What if Process 1 tries to access an address inside a page that is no present?

The hardware notifies the software via a Page Fault Exception.

It is then usually up to the OS to register an exception handler to decide what has to be done.

It is possible that accessing a page that is not on the table is a programming error:

    int is[1];
    is[2] = 1;

but there may be cases in which it is acceptable, for example in Linux when:

- the program wants to increase its stack.

    It just tries to accesses a certain byte in a given possible range,
    and if the OS is happy it adds that page to the process address space.

- the page was swapped to disk.

    The OS will need to do some work behind the processes back to get the page back into RAM.

    The OS can discover that this is the case based on the contents of the rest of the page table entry,
    since if the present flag is clear, the other entries of the page table entry are completely left
    for the OS to to what it wants.

    On Linux for example, when present = 0:

    - if all the fields of the page table entry are 0, invalid address.

    - else, the page has been swapped to disk, and the actual values of those fields encode the position
        of the page on the disk.

In any case, the OS needs to know which address generated the Page Fault to be able to deal with the problem.
This is why the nice IA32 developers set the value of `cr2` to that address whenever a Page Fault occurs.
The exception handler can then just look into `cr2` to get the address.

###simplifications

Simplifications to reality that make this example easier to understand:

- all real paging circuits use multi-level paging to save space,
    but this showed a simple single level scheme.

- page tables contained only two fields: a 20 bit address and a 1 bit present flag.

    Real page tables contain a total of 12 fields, and therefore other features which have been omitted.

##example: multi level paging scheme

The problem with a single level paging scheme is that it would take up too much RAM:
4G / 4K = 1M entries *per* process. If each entry is 4 bytes long, that would make 4M *per process*,
which is too much even for a desktop computer: `ps -A | wc -l` says that I am running 244 processes right now,
so that would take around 1GB of my RAM!

For this reason, x86 developers decided to use a multi level scheme
that reduces RAM usage.

The downside of this system is that is has a slightly higher access time.

In the simple 3 level paging scheme used for 32 bit processors without PAE,
the 32 address bits are divided as follows:

    | directory (10 bits) | table (10 bits) | offset (12 bits) |

Each process must have one and only one page directory associated to it,
so it will contain at least `2^10 = 1K` page directory entries,
much better than the minimum 1M required on a single level scheme.

Page tables are only allocated as needed by the OS.
Each page table has `2^10 = 1K` page directory entries

Page directories contain... page directory entries!
Page directory entries are the same as page table entries except that
*they point to RAM addresses of page tables instead of physical addresses of tables*.
Since those addresses are only 20 bits wide, page tables must be on the beginning of 4KB pages.

`cr3` now points to the location on RAM of the page directory of the current process
instead of page tables.

Page tables entries don't change at all from a single level scheme.

Page tables change from a single level scheme because:

- each process may have up to 1K page tables, one per page directory entry.
- each page table contains exactly 1K entries instead of 1M entries.

The reason for using 10 bits on the first two levels (and not, say, 12 | 8 | 12 )
is that each Page Table entry is 4 bytes long.
Then the 2^10 = 1K entries of Page directories and Page Tables will fit nicely into 4KB pages.
This means that it faster and simpler to allocate and dellocate pages for that purpose.

###address translation

Page directory given to process 1 by the OS:

    RAM location     physical address   present
    -------------    -----------------  --------
    P1D + 0     * L  0x10000            1
    P1D + 1     * L                     0
    P1D + 2     * L  0x80000            1
    P1D + 3     * L                     0
    ...                                 ...
    P1D + 0x3FF * L                     0

Page tables given to process 1 by the OS at `P1T1 = 0x10000000` (`0x10000` * 4K):

    RAM location       physical address   present
    -------------      -----------------  --------
    P1T1 + 0     * L   0x00001            1
    P1T1 + 1     * L                      0
    P1T1 + 2     * L   0x0000D            1
    ...                                   ...
    P1T1 + 0x3FF * L   0x00005            1

Page tables given to process 1 by the OS at `P1T2 = 0x80000000` (`0x80000` * 4K):

    RAM location       physical address   present
    -------------      -----------------  --------
    P1T2 + 0     * L   0x0000A            1
    P1T2 + 1     * L   0x0000C            1
    P1T2 + 2     * L                      0
    ...                                   ...
    P1T2 + 0x3FF * L   0x00003            1

where:

- P1D: initial position of page directory of process 1 on RAM.
- P1T1 and P1T2: initial position of page table 1 and page table 2 for process 1 on RAM.

So in this example the page directory and the page table could
be stored in RAM something like:

    ----------------> 0xFFFFFFFF


    ----------------> P1T2 + 0x3FF * L
    Page Table 1
    ----------------> P1T2

    ----------------> P1D + 0x3FF * L
    Page Directory 1
    ----------------> P1D


    ----------------> P1T1 + 0x3FF * L
    Page Table 2
    ----------------> P1T1

    ----------------> 0x00000000

Lets translate the linear address `0x00401004` step by step.

We suppose that `cr3 = P1D`, that is, it points to the page directory just described.

In binary the linear address is:

    0    0    8    0    1    0    0    4
    0000 0000 1000 0000 0001 0000 0000 0100

Grouping as 10 | 10 | 12 gives:

    0000000010 0000000001 000000000100
    0x2        0x1        0x4

which gives:

- page directory entry = 0x2
- page table     entry = 0x1
- offset               = 0x4

So the hardware looks for entry 2 of the page directory.

The page directory table says that the page table is located at `0x80000 * 4K = 0x80000000`.
This is the first RAM access of the process.

Since the page table entry is `0x1`, the hardware looks at entry 1 of the page table at `0x80000000`.
which tells it that the physical page is located at address `0x0000C * 4K = 0x0000C000`.
This is the second RAM access of the process.

Finally, the paging hardware adds the offset, and the final address is `0x0000C004`.

Other examples of translated addresses are:

    linear    10 10 12 split  physical
    -------   --------------- ---------
    00000001  000 000 001     00001001
    00001001  000 001 001     page fault
    003FF001  000 3FF 001     00005001
    00400000  001 000 000     page fault
    00800001  002 000 001     0000A001
    00801008  002 001 008     0000C008
    00802008  002 002 008     page fault
    00B00001  003 000 000     page fault

Page faults occur if either a page directory entry or a page table entry is not present.

If the OS wants to run another process concurrently, it would give the second process
a separate page directory, and link that directory to separate page tables.

##64 bit architectures

64 bits is still too much address for current RAM sizes, so most architectures will only use
less bits. x86_64 uses 48 bits in total for the actual addressing.

12 of those 48 bits are already reserved for the offset, which leaves 36 bits.

If a 2 level approach is taken, the best split would be two 18 bit levels.

But that would mean that the page directory would have `2^18 = 256K` entries,
which would take too much RAM ( close to a single level paging for 32 bit architectures! )

Therefore, 64 bit architectures create even further page levels, commonly 3 or 4.

For example, x86_64 uses: 4 levels in a 9 9 9 12 scheme, so that the upper level only takes up
only `2^9` higher level entries.

##PAE

Physical address extension.

With 32 bits, only 4GB RAM can be addressed.

This started becoming a limitation for large servers,
so Intel introduced the PAE mechanism to Pentium Pro.

To relieve the problem, Intel added 4 new address lines,
so that 64GB could be addressed.

Page table structure is also altered if PAE is on.
The exact way in which it is altered depends on weather PSE is on or off.

PAE is turned on and off via the `PAE` bit of `cr4`.

Even if the total addressable memory is 64GB,
individual process are still only able to use up to 4GB.
The OS can however put different processes on different 4GB chunks.

##PSE

Page size extension.

Allows for pages to be 4M ( or 2M if PAE is on ) in length instead of 4K.

PSE is turned on and off via the `PAE` bit of `cr4`.

##PAE and PSE page table schemes

If either PAE and PSE are active, different paging level schemes are used:

- no PAE and no PSE: 10 | 10 | 12

- no PAE and    PSE: 10 | 22.

    22 is the offset within the 4Mb page, since 22 bits address 4Mb.

- PAE and no PSE: 2 | 9 | 9 | 12

    The design reason why 9 is used twice instead of 10 is that now entries cannot fit anymore into 32 bits,
    which were all filled up by 20 address bits and 12 meaningful or reserved flag bits.

    The reason is that 20 bits are not enough anymore to represent the address of page tables:
    24 bits are now needed because of the 4 extra wires added to the processor.

    Therefore, the designers decided to increase entry size to 64 bits, and to make them fit into
    a single page table it is necessary reduce the number of entries to 2^9 instead of 2^10.

    The starting 2 is a new Page level called Page Directory Pointer Table (PDPT),
    since it *points* to page directories and fill in the 32 bit linear address.
    PDPTs are also 64 bits wide.

    `cr3` now points to PDPTs which must be on the fist four 4GB of memory and aligned on 32 bit multiples for addressing efficiency.
    This means that now `cr3` has 27 significative bits instead of 20:
    2^5 for the 32 multiples * 2^27 to complete the 2^32 of the first 4GB.

- PAE and PSE: 2 | 9 | 21

    Designers decided to keep a 9 bit wide field to make it fit into a single page.

    This leaves 23 bits. Leaving 2 for the PDPT to keep things uniform with the PAE case without PSE leaves 21 for offset,
    meaning that pages are 2M wide instead of 4M.

##TLB

The Translation Lookahead Buffer (TLB) is a cache for paging addresses.

Since it is a cache, it shares many of the design issues of the CPU cache,
such as associativity level.

This section shall describe a simplified fully associative TLB with 4 single address entries.
Note that like other caches, real TLBs are not usually fully associative.

###basic operation

After a translation between linear and physical address happens,
it is stored on the TLB. For example, a 4 entry TLB starts in the following state:

      valid   linear   physical
      ------  -------  ---------
    > 0       00000    00000
      0       00000    00000
      0       00000    00000
      0       00000    00000

The `>` indicates the current entry to be replaced.

and after a page linear address `00003` is translated to a physical address `00005`,
the TLB becomes:

      valid   linear   physical
      ------  -------  ---------
      1       00003    00005
    > 0       00000    00000
      0       00000    00000
      0       00000    00000

and after a second translation of `00007` to `00009` it becomes:

      valid   linear   physical
      ------  -------  ---------
      1       00003    00005
      1       00007    00009
    > 0       00000    00000
      0       00000    00000

Now if `00003` needs to be translated again, hardware first looks up the TLB
and finds out its address with a single RAM access `00003 --> 00005`.

Of course, `00000` is not on the TLB since on valid entries contain `00000` as key.

###replacement policy

When TLB is filled up, older addresses are overwritten.
Just like for CPU cache, the replacement policy is a potentially complex operation,
but a simple and reasonable heuristic is to remove the least recently used entry (LRU).

With LRU, starting from state:

      valid   linear   physical
      ------  -------  ---------
    > 1       00003    00005
      1       00007    00009
      1       00009    00001
      1       0000B    00003

adding `0000D -> 0000A` would give:

      valid   linear   physical
      ------  -------  ---------
      1       0000D    0000A
    > 1       00007    00009
      1       00009    00001
      1       0000B    00003

###CAM

Using the TLB makes translation faster, because the initial translation takes one access
*per TLB level*, which means 2 on a simple 32 bit scheme, but 3 or 4 on 64 bit architectures.

The TLB is usually implemented as an expensive type of RAM called content-addressable memory (CAM).
CAM implements an associative map on hardware, that is,
a structure that given a key (linear address), retrieves a value.

Mappings could also be implemented on RAM addresses, but CAM mappings may required much less
entries than a RAM mapping.

For example, a map in which:

- both keys and values have 20 bits (the case of a simple paging schemes)
- at most 4 values need to be stored at each time

could be stored in a TLB with 4 entries:

    linear   physical
    -------  ---------
    00000    00001
    00001    00010
    00010    00011
    FFFFF    00000

However, to implement this with RAM, *it would be necessary to have 2^20 addresses*:

    linear   physical
    -------  ---------
    00000    00001
    00001    00010
    00010    00011
    ... (from 00011 to FFFFE)
    FFFFF    00000

which would be even more expensive than using a TLB.

###invalidating entries

When `cr3` changes, all TLB entries are invalidated,
because a new page table for a new process is going to be used, so it is unlikely
that any of the old entries have any meaning.

The x86 also offers the `invlpg` instruction which explicitly invalidates a single TLB entry.
Other architectures offer even more instructions to invalidated TLB entries,
such as invalidating all entries on a given range.

##bibliography

Free:

[rutgers-pxk-416]: http://www.cs.rutgers.edu/~pxk/416/notes/

- [rutgers-pxk-416][] chapter "Memory management: lecture notes"

    Good historical review of memory organization techniques used by older OS.

Non-free:

[bovet05]: http://www.amazon.com/books/dp/0596005652

- [bovet05][] chapter "Memory addressing"

    Reasonable intro to x86 memory addressing. Missing some good and simple examples.

#interrupts

the processor has a pin which receives interrupts

whenever an interrupt is received, a piece of code defined by the user
is executed. This piece of code is called an interrupt service routine (ISR)

the interrupt has a number which can vary from 0 to 255 and which helps
identify the interrupt

there are 3 main applications to interrupts:

- system calls on both linux and windows are called via interrupts generated by user programs
    via the `int` instruction

- when a program must wait for some hardware input such as key press, it lets other programs
    run, and when the keypress is done this generates an interrupt from hardware origin.

    this dispenses the program from periodically checking if the input has finally come or not (pooling)
    and thus consuming CPU time for nothing.

- exceptions for error handling

    certain operations such as division by 0 or trying to access memory without permission
    generates an interrupt called an exception.

    the exception code allows the programmer to deal with the error.

    interrupts between 0x0 and 0x1F are reserved for processor exceptions. list: <http://en.wikipedia.org/wiki/Interrupt_descriptor_table>

the instructions which deal with interrupts are:

- `int n`: generate a software interrupt. Used to make system calls.
- `ireX n`: generate interrupt n if flag X is set
- `iret`: return from current ISR to old code

TODO how to register an ISR

TODO check the predefined INT 10 and other predefined ones! <http://en.wikipedia.org/wiki/INT_10H>

#simd

Single instruction multiple data.

Do exactly what the name says, for example, 4 multiplications on a single CPU cycle!

It is in general hard to manually port code that was not originally designed to use SIMD instructions
and the same goes for compilers.

Introduced later as extensions to the original x86.

Sources:

- <http://en.wikibooks.org/wiki/X86_Assembly/SSE>
- <http://www.songho.ca/misc/sse/sse.html>

MMX, SSE, SSE2, SSE3, SSSE3, SSE4 are the version names

SIMD instructions use the following registers:

- 8 64 bit registers called MMX[0-7]
- 8 128 bit registers called XMM[0-7]
- 1 MXCSR

in this way you can add, subtract, multiply, etc 4 floats/2 doubles at once
disconsidering overeads you can go up to 4x faster

as all of assembler, you will have a hard time beating modern compiler optimizers
with this, so beware... still lots of fun though!

you have to try to align data on 16 bytes to make instructions go faster
this is done with the align directive

#driver io instructions

the following instructions are used to communicate with hardware such as hard disks
mouses and so on. They cannot be used on user level programs.

- IN            Read from a port
- OUT           Write to a port
- INS/INSB      Input string from port/Input byte string from port
- INS/INSW      Input string from port/Input word string from port
- INS/INSD      Input string from port/Input doubleword string from port
- OUTS/OUTSB    Output string to port/Output byte string to port
- OUTS/OUTSW    Output string to port/Output word string to port
- OUTS/OUTSD    Output string to port/Output doubleword string to port
